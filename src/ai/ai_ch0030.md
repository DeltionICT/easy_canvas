---
title: Projecten
date: 2025-10-07
---
::: section
### Projecten
In dit onderdeel vind je projecten die je kunt doen om te oefenen met AI en Python. Je kunt ook zelf een project bedenken of een project gebruiken maar aanpassen naar een onderwerp dat voor jou relevant is. 
:::
::: section
### Structured output Projecten

#### De Gestructureerde Samenvatter (De Perfecte JSON-Tool)

  * **Het Probleem:** AI's schrijven vaak lange samenvattingen, maar je hebt alleen de kernfeiten nodig in een vaste database-structuur.
  * **De Tool:** Bouw een Python-script met **FastAPI** (voor de API-interface) dat een stuk tekst (bijvoorbeeld een nieuwsartikel of een klant-e-mail) als input neemt.
  * **De AI-Actie:** Je definieert een Pydantic-klasse, bijvoorbeeld `ArtikelSamenvatting`, met vaste velden:
    ```python
    class ArtikelSamenvatting(BaseModel):
        hoofd_onderwerp: str
        urgentie_score: int # Van 1 tot 10
        actiepunten: List[str]
        sentiment: Literal["positief", "neutraal", "negatief"]
    ```
  * **De Output:** Je gebruikt een LLM API om de input-tekst te analyseren en de AI te dwingen de output **exact** in dit Pydantic-formaat te leveren (structured output).
  * **De Winst:** Je hebt nu een betrouwbare tool die willekeurige tekst omzet in opslagbare en filterbare data.


#### Code-Refactor Suggesties Tool (De Slimme Code Reviewer)

Als software developer is dit een project met directe meerwaarde. Je richt je op het analyseren van Python-code en het geven van gestructureerde verbeteringen.

  * **Het Probleem:** Het handmatig controleren van code op kleine verbeteringen (bijv. type-hints toevoegen of onnodige importen verwijderen) kost tijd.
  * **De Tool:** Creëer een tool die een Python-bestand leest en dit naar de AI stuurt met de vraag om refactoring-suggesties.
  * **De AI-Actie:** Je Pydantic-schema dwingt de AI om elke suggestie op deze manier terug te geven:
    ```python
    class RefactorSuggestie(BaseModel):
        regel_nummer: int
        oorspronkelijke_code: str
        verbeterde_code: str
        uitleg: str
    ```
  * **De Output:** Je programma kan de lijst met `RefactorSuggestie`-objecten doorlopen en bijvoorbeeld automatisch een overzichtelijke Markdown-tabel genereren, of zelfs direct een *pull request* voorbereiden.
  * **Uitbreiding:** Gebruik **Docker** om deze tool eenvoudig te draaien op een CI/CD-server.


#### Dynamische Vragenlijst Generator (De Formulier-Automatisator)

Veel data is nog steeds ongestructureerd. Je kunt de AI een formulier laten bouwen dat past bij de content.

  * **Het Probleem:** Je hebt een lange transcriptie van een klantgesprek en je wilt snel een paar specifieke vragen kunnen beantwoorden, maar de vragen staan nog niet vast.
  * **De Tool:** Neem een lange tekst (bijv. een document of een verslag) als input. De AI moet een relevante vragenlijst genereren om de essentie van het document te toetsen.
  * **De AI-Actie:** Het schema zorgt voor een gestructureerde lijst met vragen en de document-locatie van het antwoord:
    ```python
    class Vragenlijst(BaseModel):
        titel: str
        vragen: List[str]

    # Of een tweede stap waarbij de AI de antwoorden in het document zoekt:
    class DocumentAntwoord(BaseModel):
        vraag: str
        gevonden_antwoord: str
        pagina_nummer_of_sectie: Optional[str]
    ```
  * **De Winst:** Je hebt een tool die de AI gebruikt om snel de belangrijkste informatie uit willekeurige documenten te destilleren en te structureren, ideaal voor bijvoorbeeld het verwerken van juridische teksten of technische handleidingen.
:::

::: section
### RAG Projecten
#### Interne Documentatie Zoekmachine
Dit is een klassiek RAG-project met directe bedrijfswaarde. Je lost het probleem op dat belangrijke informatie verspreid ligt over honderden documenten.
* Het Probleem: Technische handleidingen, HR-beleid en verslagen zijn opgeslagen als ongestructureerde PDF's of tekstbestanden. Vragen beantwoorden is traag.
* De Projectfocus: Bouw een systeem dat de documenten opsplitst in kleine stukjes (chunks), deze omzet in vector embeddings, en opslaat in een PostgreSQL-database met behulp van de pgvector extensie (een must-have voor RAG met Postgres).

**De Architectuur:**
* Met `pypdf` of `python-docx`: Voor het extraheren van ruwe tekst uit PDF- of Word-bestanden.
* LangChain (Text Splitters): Hoewel LangChain een groter framework is, is de module voor Text Splitting (chunks maken) de industriestandaard en zeer efficiënt (bijv. RecursiveCharacterTextSplitter).
* Embeddings (Transform): Sentence-transformers: Dit is de meest gangbare en gebruiksvriendelijke bibliotheek om tekst om te zetten in vector embeddings (een lijst van getallen). Je laadt hier eenvoudig een geschikt model mee, zoals bijvoorbeeld all-MiniLM-L6-v2.
* Database Connectiviteit (Load): psycopg2 of asyncpg: Python-drivers om verbinding te maken met je PostgreSQL-database en SQL-commando's uit te voeren.
* SQLAlchemy (optioneel): Handig als je object-relational mapping (ORM) wilt gebruiken in plaats van pure SQL.
* Query (Het Latere Gebruik) Hoewel dit buiten de ETL-pipeline valt, is dit het doel van de hele operatie.
  * Een gebruiker stelt een vraag (bijv. "Wat is het beleid voor thuiswerken?"). Je genereert een vector van deze vraag met hetzelfde sentence-transformers model.
  * Vector Search: Je voert een SELECT query uit op PostgreSQL, waarbij je de afstand berekent tussen de vraagvector en alle chunk-vectoren in je tabel. Je gebruikt hiervoor de speciale pgvector operatoren (bijv. ORDER BY embedding <-> vraag_vector LIMIT 5).
  * RAG Generatie: Je stuurt de 5 meest relevante tekstfragmenten (de chunks) samen met de oorspronkelijke vraag naar de LLM om het definitieve antwoord te genereren (de Generation).

#### Real-time Productcatalogus
Dit project richt zich op het dynamisch ophalen van feitelijke data, wat de ware kracht van RAG laat zien wanneer het gekoppeld is aan een relationele database.
* Het Probleem: Klanten stellen complexe, specifieke vragen over productvoorraad, prijzen, of specificaties die te vaak veranderen om in de training van een LLM te zitten.
* De Projectfocus: De RAG-data is de feitelijke productdata uit je PostgreSQL-tabellen (prijs, voorraad, SKU, beschrijving). Je gebruikt de AI om natuurlijke taalvragen te beantwoorden door de feitelijke data op te halen.

**De Architectuur:**
* PostgreSQL Data: De database bevat de gestructureerde productinformatie.
* RAG & LLM Integration: Wanneer een gebruiker vraagt: "Wat is de prijs van de groene laptop die op voorraad is in Amsterdam?", kan de AI:
  * Optie A (Text Embeddings): De vraag omzetten in een vector en matchen met de productbeschrijvingen/metadata in pgvector.
  * Optie B (Tool Use/Function Calling): De AI genereren om een gestructureerde SQL-query te bouwen, die je Python-code uitvoert op de PostgreSQL-database.
* Pydantic-Output: De AI verwerkt de opgevraagde (en actuele) data en presenteert een gestructureerd antwoord:

```python
  class PrijsEnVoorraad(BaseModel):
      productnaam: str
      actuele_prijs: float
      voorraad_locatie: str

```    
:::

::: section
### Docker MCP
In dit project ga je demonstreren hoe je met Docker Model Context Protocol een systeem kunt maken dat gebruik maakt van de MCP servers voor "Obsidian" en "DuckDuckGo". Je stelt een vraag aan AI om iets op te zoeken op het internet en het resultaat te plaatsen in een markdown-document.

#### De belangrijkste stappen van de demonstratie:

1.  **Opzetten van de Omgeving:** De demonstratie maakt lokaal gebruik van **Docker Desktop** met de **MCP Toolkit** ingeschakeld.
2.  **Installatie van de MCP Server:** Een officiële **Obsidian MCP server** wordt toegevoegd vanuit de Docker-catalogus.
3.  **Configuratie van de Server:** Voor Obsidian is een **API-sleutel** nodig die wordt verkregen via een community-plugin (local REST API) in Obsidian en vervolgens in het configuratieveld van de MCP server wordt geplakt.
4.  **Connectie met de Client:** De LLM-applicatie **Claude Desktop** wordt als client verbonden met de Docker MCP gateway.
:::